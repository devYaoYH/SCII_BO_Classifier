{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import datetime\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from zipUtil import zip_write, zip_read\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_config import decode_type, PROTOSS_ACTIONS, PROTOSS_ACTIONS_TYPE, TERRAN_ACTIONS, TERRAN_ACTIONS_TYPE, ZERG_ACTIONS, ZERG_ACTIONS_TYPE\n",
    "ACTIONS = {'P': PROTOSS_ACTIONS, 'T': TERRAN_ACTIONS, 'Z': ZERG_ACTIONS}\n",
    "rev_ACTIONS = {race: {v:k for k,v in ACTIONS[race].items()} for race in 'PTZ'}\n",
    "ACTIONS_TYPE = {'P': PROTOSS_ACTIONS_TYPE, 'T': TERRAN_ACTIONS_TYPE, 'Z': ZERG_ACTIONS_TYPE}\n",
    "GATHERER_NAMES = {'P': 'Probe', 'T': 'SCV', 'Z': 'Drone'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the dataset dictionaries\n",
    "con_dfs = zip_read('dataframes_continuous')\n",
    "dis_dfs = zip_read('dataframes_discrete')\n",
    "target_dfs = zip_read('dataframes_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset cleanup\n",
    "for race in \"PTZ\":\n",
    "    # Clean up some useless columns\n",
    "    try:\n",
    "        con_dfs[race] = con_dfs[race].drop(columns=['vespene_queued_economic','vespene_total_economic','vespene_value_current_economic'])\n",
    "    except:\n",
    "        pass\n",
    "    # Clean up incorrectly labeled columns\n",
    "    incorrect_labels = target_dfs[race][~target_dfs[race]['Target'].isin(rev_ACTIONS[race])].index.tolist()\n",
    "    if (len(incorrect_labels) > 0):\n",
    "        print(f\"{race} dropping {len(incorrect_labels)} rows due to incorrect labelling\")\n",
    "        print(target_dfs[race]['Target'][incorrect_labels])\n",
    "        con_dfs[race] = con_dfs[race].drop(incorrect_labels)\n",
    "        dis_dfs[race] = dis_dfs[race].drop(incorrect_labels)\n",
    "        target_dfs[race] = target_dfs[race].drop(incorrect_labels)\n",
    "    # Move ['Timestamp','supply_available','supply_consumed'] fields from continuous dataset into discrete dataset\n",
    "    discrete_features = ['Timestamp','supply_available','supply_consumed']\n",
    "    dis_dfs[race] = pd.concat([dis_dfs[race],con_dfs[race][discrete_features]],axis=1)\n",
    "    con_dfs[race] = con_dfs[race].drop(columns=discrete_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remap fine-grained action labels into broader action-class labels (as defined in dataset_config.py)\n",
    "# 0b[UABETD] 6-bit encoding\n",
    "# U: is_upgrade?\n",
    "# A: is_army?\n",
    "# B: is_building?\n",
    "# E: for_economy?\n",
    "# T: for_tech?\n",
    "# D: for_defense? (static defenses only)\n",
    "def map_to_action_type(Y_labels,race):\n",
    "    return np.array([ACTIONS_TYPE[race][rev_ACTIONS[race][lbl]] for lbl in Y_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to independently (naively) mix prediction probabilities\n",
    "# from multiple naive bayes classifiers\n",
    "def mix_naive_bayes(modalities,n_samples,classes):\n",
    "    probs = np.ones((n_samples,len(classes)))\n",
    "    for clf, X_test in modalities:\n",
    "        probs *= clf.predict_proba(X_test)\n",
    "    result = np.array([classes[i] for i in np.argmax(probs,axis=1)])\n",
    "    print(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "race = 'P'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4  4 12 ... 16 16 16] 7\n"
     ]
    }
   ],
   "source": [
    "# Full dataset\n",
    "X_con = con_dfs[race]\n",
    "X_dis = dis_dfs[race]\n",
    "Y = target_dfs[race]['Target'].to_numpy()\n",
    "# Combining the two modalities\n",
    "full_index = target_dfs[race].index.tolist()\n",
    "# Shuffle into random order\n",
    "random.seed(0)\n",
    "random.shuffle(full_index)\n",
    "# Cut into 80/20 split\n",
    "cutoff = int(0.80*len(full_index))\n",
    "train_index = full_index[:cutoff]\n",
    "test_index = full_index[cutoff:]\n",
    "\n",
    "X_train_con, X_train_dis = con_dfs[race].loc[train_index], dis_dfs[race].loc[train_index]\n",
    "X_test_con, X_test_dis = con_dfs[race].loc[test_index], dis_dfs[race].loc[test_index]\n",
    "Y_train = target_dfs[race].loc[train_index]\n",
    "Y_test = target_dfs[race].loc[test_index]\n",
    "\n",
    "# Transform target labels into numpy array\n",
    "Y_train = Y_train['Target'].to_numpy()\n",
    "Y_test = Y_test['Target'].to_numpy()\n",
    "\n",
    "# Remap to coarse label classes\n",
    "Y_types = map_to_action_type(Y,race)\n",
    "print(Y_types,len(set(Y_types)))\n",
    "Y_train_types = map_to_action_type(Y_train,race)\n",
    "Y_test_types = map_to_action_type(Y_test,race)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000100\n",
      "\tWorker\n",
      "\t0.399, 40262\n",
      "010000\n",
      "\tArmy\n",
      "\t0.276, 27789\n",
      "001100\n",
      "\tEconomy\n",
      "\tBuilding\n",
      "\t0.163, 16399\n",
      "011000\n",
      "\tBuilding\n",
      "\tArmy\n",
      "\t0.063, 6316\n",
      "001001\n",
      "\tStatic Defense\n",
      "\tBuilding\n",
      "\t0.041, 4091\n",
      "001010\n",
      "\tTechnology\n",
      "\tBuilding\n",
      "\t0.035, 3513\n",
      "100000\n",
      "\tUpgrade\n",
      "\t0.024, 2439\n"
     ]
    }
   ],
   "source": [
    "# Some prior occurance stats for each label type\n",
    "lbl_count = defaultdict(int)\n",
    "for i in Y_types:\n",
    "    lbl_count[i] += 1\n",
    "lbl_stats = sorted([(lbl_count[i]/len(Y_types),i) for i in lbl_count.keys()],reverse=True)\n",
    "for ratio,lbl in lbl_stats:\n",
    "    decode_type(lbl)\n",
    "    print(f\"\\t{ratio:.3f}, {lbl_count[lbl]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classification\n",
      "max_depth: 2\n",
      "Coarse: 0.4981648645967662\n",
      "Fine: 0.4072512647554806\n",
      "AdaBoost Classification\n",
      "n_estimators: 50\n",
      "Coarse: 0.4453923221902589\n",
      "Fine: 0.3976292034520385\n"
     ]
    }
   ],
   "source": [
    "# Random Forest classifier (control?)\n",
    "print(\"Random Forest Classification\")\n",
    "rand_forest_perf = [[],[]]\n",
    "for i in range(2,3):\n",
    "    print(f\"max_depth: {i}\")\n",
    "    clf = RandomForestClassifier(max_depth=i, random_state=0)\n",
    "    clf.fit(X_train_dis,Y_train_types)\n",
    "    coarse_score = clf.score(X_test_dis,Y_test_types)\n",
    "    print(\"Coarse:\",coarse_score)\n",
    "    clf.fit(X_train_dis,Y_train)\n",
    "    fine_score = clf.score(X_test_dis,Y_test)\n",
    "    print(\"Fine:\",fine_score)\n",
    "    rand_forest_perf[0].append(coarse_score)\n",
    "    rand_forest_perf[1].append(fine_score)\n",
    "print(\"AdaBoost Classification\")\n",
    "ada_boost_perf = [[],[]]\n",
    "for n in range(50,51,50):\n",
    "    print(f\"n_estimators: {n}\")\n",
    "    clf = AdaBoostClassifier(n_estimators=n, random_state=0)\n",
    "    clf.fit(X_train_dis,Y_train_types)\n",
    "    coarse_score = clf.score(X_test_dis,Y_test_types)\n",
    "    print(\"Coarse:\",coarse_score)\n",
    "    clf.fit(X_train_dis,Y_train)\n",
    "    fine_score = clf.score(X_test_dis,Y_test)\n",
    "    print(\"Fine:\",fine_score)\n",
    "    ada_boost_perf[0].append(coarse_score)\n",
    "    ada_boost_perf[1].append(fine_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction using ONLY Continuous Features\n",
      "Gaussian\n",
      "Coarse Predictions: 0.44752504711834146\n",
      "Fine Predictions: 0.06551929372086103\n",
      "Multinomial\n",
      "Coarse Predictions: 0.3750619978176768\n",
      "Fine Predictions: 0.02341037595476639\n",
      "Complement\n",
      "Coarse Predictions: 0.4772344013490725\n",
      "Fine Predictions: 0.3459478226366432\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction using ONLY Continuous Features\")\n",
    "for clf, name in zip([GaussianNB(),MultinomialNB(),ComplementNB()], ['Gaussian', 'Multinomial', 'Complement']):\n",
    "    print(name)\n",
    "    clf.fit(X_train_con,Y_train_types)\n",
    "    s = clf.score(X_test_con,Y_test_types)\n",
    "    print(f\"Coarse Predictions: {s}\")\n",
    "    clf.fit(X_train_con,Y_train)\n",
    "    s = clf.score(X_test_con,Y_test)\n",
    "    print(f\"Fine Predictions: {s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction using ONLY Discrete Features\n",
      "Gaussian\n",
      "Coarse Predictions: 0.39921634758456503\n",
      "Fine Predictions: 0.02187283007638131\n",
      "Multinomial\n",
      "Coarse Predictions: 0.471282610852098\n",
      "Fine Predictions: 0.22120821347088582\n",
      "Complement\n",
      "Coarse Predictions: 0.4906755282214066\n",
      "Fine Predictions: 0.41945243527427833\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction using ONLY Discrete Features\")\n",
    "for clf, name in zip([GaussianNB(),MultinomialNB(),ComplementNB()], ['Gaussian', 'Multinomial', 'Complement']):\n",
    "    print(name)\n",
    "    clf.fit(X_train_dis,Y_train_types)\n",
    "    s = clf.score(X_test_dis,Y_test_types)\n",
    "    print(f\"Coarse Predictions: {s}\")\n",
    "    clf.fit(X_train_dis,Y_train)\n",
    "    s = clf.score(X_test_dis,Y_test)\n",
    "    print(f\"Fine Predictions: {s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4 16 16 ... 16  4  4]\n",
      "Mixture 0.4772344013490725\n"
     ]
    }
   ],
   "source": [
    "clf_con, clf_dis = GaussianNB(), ComplementNB()\n",
    "clf_con.fit(X_train_con,Y_train_types)\n",
    "clf_dis.fit(X_train_dis,Y_train_types)\n",
    "label_classes = clf_con.classes_\n",
    "print(\"Mixture\",np.mean(mix_naive_bayes([(clf_con,X_test_con),(clf_dis,X_test_dis)],len(X_test_con),label_classes) == Y_test_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "race = 'T'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4  4 12 ...  4  4  4] 8\n"
     ]
    }
   ],
   "source": [
    "# Full dataset\n",
    "X_con = con_dfs[race]\n",
    "X_dis = dis_dfs[race]\n",
    "Y = target_dfs[race]['Target'].to_numpy()\n",
    "# Combining the two modalities\n",
    "full_index = target_dfs[race].index.tolist()\n",
    "# Shuffle into random order\n",
    "random.seed(0)\n",
    "random.shuffle(full_index)\n",
    "# Cut into 80/20 split\n",
    "cutoff = int(0.80*len(full_index))\n",
    "train_index = full_index[:cutoff]\n",
    "test_index = full_index[cutoff:]\n",
    "\n",
    "X_train_con, X_train_dis = con_dfs[race].loc[train_index], dis_dfs[race].loc[train_index]\n",
    "X_test_con, X_test_dis = con_dfs[race].loc[test_index], dis_dfs[race].loc[test_index]\n",
    "Y_train = target_dfs[race].loc[train_index]\n",
    "Y_test = target_dfs[race].loc[test_index]\n",
    "\n",
    "# Transform target labels into numpy array\n",
    "Y_train = Y_train['Target'].to_numpy()\n",
    "Y_test = Y_test['Target'].to_numpy()\n",
    "\n",
    "# Remap to coarse label classes\n",
    "Y_types = map_to_action_type(Y,race)\n",
    "print(Y_types,len(set(Y_types)))\n",
    "Y_train_types = map_to_action_type(Y_train,race)\n",
    "Y_test_types = map_to_action_type(Y_test,race)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "010000\n",
      "\tArmy\n",
      "\t0.369, 30351\n",
      "000100\n",
      "\tWorker\n",
      "\t0.352, 28964\n",
      "001100\n",
      "\tEconomy\n",
      "\tBuilding\n",
      "\t0.157, 12887\n",
      "011000\n",
      "\tBuilding\n",
      "\tArmy\n",
      "\t0.042, 3490\n",
      "011010\n",
      "\tTechnology\n",
      "\tBuilding\n",
      "\tArmy\n",
      "\t0.033, 2696\n",
      "100000\n",
      "\tUpgrade\n",
      "\t0.019, 1569\n",
      "001001\n",
      "\tStatic Defense\n",
      "\tBuilding\n",
      "\t0.017, 1416\n",
      "001010\n",
      "\tTechnology\n",
      "\tBuilding\n",
      "\t0.012, 947\n"
     ]
    }
   ],
   "source": [
    "# Some prior occurance stats for each label type\n",
    "lbl_count = defaultdict(int)\n",
    "for i in Y_types:\n",
    "    lbl_count[i] += 1\n",
    "lbl_stats = sorted([(lbl_count[i]/len(Y_types),i) for i in lbl_count.keys()],reverse=True)\n",
    "for ratio,lbl in lbl_stats:\n",
    "    decode_type(lbl)\n",
    "    print(f\"\\t{ratio:.3f}, {lbl_count[lbl]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classification\n",
      "max_depth: 2\n",
      "Coarse: 0.5078352769679301\n",
      "Fine: 0.4253522837706511\n",
      "AdaBoost Classification\n",
      "n_estimators: 50\n",
      "Coarse: 0.4579689018464529\n",
      "Fine: 0.42128279883381925\n"
     ]
    }
   ],
   "source": [
    "# Random Forest classifier (control?)\n",
    "print(\"Random Forest Classification\")\n",
    "rand_forest_perf = [[],[]]\n",
    "for i in range(2,3):\n",
    "    print(f\"max_depth: {i}\")\n",
    "    clf = RandomForestClassifier(max_depth=i, random_state=0)\n",
    "    clf.fit(X_train_dis,Y_train_types)\n",
    "    coarse_score = clf.score(X_test_dis,Y_test_types)\n",
    "    print(\"Coarse:\",coarse_score)\n",
    "    clf.fit(X_train_dis,Y_train)\n",
    "    fine_score = clf.score(X_test_dis,Y_test)\n",
    "    print(\"Fine:\",fine_score)\n",
    "    rand_forest_perf[0].append(coarse_score)\n",
    "    rand_forest_perf[1].append(fine_score)\n",
    "print(\"AdaBoost Classification\")\n",
    "ada_boost_perf = [[],[]]\n",
    "for n in range(50,51,50):\n",
    "    print(f\"n_estimators: {n}\")\n",
    "    clf = AdaBoostClassifier(n_estimators=n, random_state=0)\n",
    "    clf.fit(X_train_dis,Y_train_types)\n",
    "    coarse_score = clf.score(X_test_dis,Y_test_types)\n",
    "    print(\"Coarse:\",coarse_score)\n",
    "    clf.fit(X_train_dis,Y_train)\n",
    "    fine_score = clf.score(X_test_dis,Y_test)\n",
    "    print(\"Fine:\",fine_score)\n",
    "    ada_boost_perf[0].append(coarse_score)\n",
    "    ada_boost_perf[1].append(fine_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction using ONLY Continuous Features\n",
      "Gaussian\n",
      "Coarse Predictions: 0.34566326530612246\n",
      "Fine Predictions: 0.0614067055393586\n",
      "Multinomial\n",
      "Coarse Predictions: 0.17280126336248786\n",
      "Fine Predictions: 0.01888969873663751\n",
      "Complement\n",
      "Coarse Predictions: 0.48226433430515064\n",
      "Fine Predictions: 0.3923712342079689\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction using ONLY Continuous Features\")\n",
    "for clf, name in zip([GaussianNB(),MultinomialNB(),ComplementNB()], ['Gaussian', 'Multinomial', 'Complement']):\n",
    "    print(name)\n",
    "    clf.fit(X_train_con,Y_train_types)\n",
    "    s = clf.score(X_test_con,Y_test_types)\n",
    "    print(f\"Coarse Predictions: {s}\")\n",
    "    clf.fit(X_train_con,Y_train)\n",
    "    s = clf.score(X_test_con,Y_test)\n",
    "    print(f\"Fine Predictions: {s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction using ONLY Discrete Features\n",
      "Gaussian\n",
      "Coarse Predictions: 0.05369290573372206\n",
      "Fine Predictions: 0.024963556851311953\n",
      "Multinomial\n",
      "Coarse Predictions: 0.47819484936831874\n",
      "Fine Predictions: 0.1553692905733722\n",
      "Complement\n",
      "Coarse Predictions: 0.4959305150631681\n",
      "Fine Predictions: 0.42346938775510207\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction using ONLY Discrete Features\")\n",
    "for clf, name in zip([GaussianNB(),MultinomialNB(),ComplementNB()], ['Gaussian', 'Multinomial', 'Complement']):\n",
    "    print(name)\n",
    "    clf.fit(X_train_dis,Y_train_types)\n",
    "    s = clf.score(X_test_dis,Y_test_types)\n",
    "    print(f\"Coarse Predictions: {s}\")\n",
    "    clf.fit(X_train_dis,Y_train)\n",
    "    s = clf.score(X_test_dis,Y_test)\n",
    "    print(f\"Fine Predictions: {s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32  4 32 ... 32 32  4]\n",
      "Mixture 0.42073615160349853\n"
     ]
    }
   ],
   "source": [
    "clf_con, clf_dis = GaussianNB(), ComplementNB()\n",
    "clf_con.fit(X_train_con,Y_train_types)\n",
    "clf_dis.fit(X_train_dis,Y_train_types)\n",
    "label_classes = clf_con.classes_\n",
    "print(\"Mixture\",np.mean(mix_naive_bayes([(clf_con,X_test_con),(clf_dis,X_test_dis)],len(X_test_con),label_classes) == Y_test_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "race = 'Z'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4 12  4 ... 16 16 16] 7\n"
     ]
    }
   ],
   "source": [
    "# Full dataset\n",
    "X_con = con_dfs[race]\n",
    "X_dis = dis_dfs[race]\n",
    "Y = target_dfs[race]['Target'].to_numpy()\n",
    "# Combining the two modalities\n",
    "full_index = target_dfs[race].index.tolist()\n",
    "# Shuffle into random order\n",
    "random.seed(0)\n",
    "random.shuffle(full_index)\n",
    "# Cut into 80/20 split\n",
    "cutoff = int(0.80*len(full_index))\n",
    "train_index = full_index[:cutoff]\n",
    "test_index = full_index[cutoff:]\n",
    "\n",
    "X_train_con, X_train_dis = con_dfs[race].loc[train_index], dis_dfs[race].loc[train_index]\n",
    "X_test_con, X_test_dis = con_dfs[race].loc[test_index], dis_dfs[race].loc[test_index]\n",
    "Y_train = target_dfs[race].loc[train_index]\n",
    "Y_test = target_dfs[race].loc[test_index]\n",
    "\n",
    "# Transform target labels into numpy array\n",
    "Y_train = Y_train['Target'].to_numpy()\n",
    "Y_test = Y_test['Target'].to_numpy()\n",
    "\n",
    "# Remap to coarse label classes\n",
    "Y_types = map_to_action_type(Y,race)\n",
    "print(Y_types,len(set(Y_types)))\n",
    "Y_train_types = map_to_action_type(Y_train,race)\n",
    "Y_test_types = map_to_action_type(Y_test,race)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "010000\n",
      "\tArmy\n",
      "\t0.334, 29438\n",
      "000100\n",
      "\tWorker\n",
      "\t0.322, 28356\n",
      "001100\n",
      "\tEconomy\n",
      "\tBuilding\n",
      "\t0.198, 17472\n",
      "001010\n",
      "\tTechnology\n",
      "\tBuilding\n",
      "\t0.050, 4429\n",
      "010100\n",
      "\tEconomy\n",
      "\tArmy\n",
      "\t0.045, 3956\n",
      "100000\n",
      "\tUpgrade\n",
      "\t0.030, 2671\n",
      "001001\n",
      "\tStatic Defense\n",
      "\tBuilding\n",
      "\t0.021, 1834\n"
     ]
    }
   ],
   "source": [
    "# Some prior occurance stats for each label type\n",
    "lbl_count = defaultdict(int)\n",
    "for i in Y_types:\n",
    "    lbl_count[i] += 1\n",
    "lbl_stats = sorted([(lbl_count[i]/len(Y_types),i) for i in lbl_count.keys()],reverse=True)\n",
    "for ratio,lbl in lbl_stats:\n",
    "    decode_type(lbl)\n",
    "    print(f\"\\t{ratio:.3f}, {lbl_count[lbl]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classification\n",
      "max_depth: 2\n",
      "Coarse: 0.5022118874773139\n",
      "Fine: 0.39462341197822143\n",
      "AdaBoost Classification\n",
      "n_estimators: 50\n",
      "Coarse: 0.5183756805807622\n",
      "Fine: 0.33325771324863884\n"
     ]
    }
   ],
   "source": [
    "# Random Forest classifier (control?)\n",
    "print(\"Random Forest Classification\")\n",
    "rand_forest_perf = [[],[]]\n",
    "for i in range(2,3):\n",
    "    print(f\"max_depth: {i}\")\n",
    "    clf = RandomForestClassifier(max_depth=i, random_state=0)\n",
    "    clf.fit(X_train_dis,Y_train_types)\n",
    "    coarse_score = clf.score(X_test_dis,Y_test_types)\n",
    "    print(\"Coarse:\",coarse_score)\n",
    "    clf.fit(X_train_dis,Y_train)\n",
    "    fine_score = clf.score(X_test_dis,Y_test)\n",
    "    print(\"Fine:\",fine_score)\n",
    "    rand_forest_perf[0].append(coarse_score)\n",
    "    rand_forest_perf[1].append(fine_score)\n",
    "print(\"AdaBoost Classification\")\n",
    "ada_boost_perf = [[],[]]\n",
    "for n in range(50,51,50):\n",
    "    print(f\"n_estimators: {n}\")\n",
    "    clf = AdaBoostClassifier(n_estimators=n, random_state=0)\n",
    "    clf.fit(X_train_dis,Y_train_types)\n",
    "    coarse_score = clf.score(X_test_dis,Y_test_types)\n",
    "    print(\"Coarse:\",coarse_score)\n",
    "    clf.fit(X_train_dis,Y_train)\n",
    "    fine_score = clf.score(X_test_dis,Y_test)\n",
    "    print(\"Fine:\",fine_score)\n",
    "    ada_boost_perf[0].append(coarse_score)\n",
    "    ada_boost_perf[1].append(fine_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction using ONLY Continuous Features\n",
      "Gaussian\n",
      "Coarse Predictions: 0.3626361161524501\n",
      "Fine Predictions: 0.04469147005444646\n",
      "Multinomial\n",
      "Coarse Predictions: 0.30473003629764067\n",
      "Fine Predictions: 0.030399274047186932\n",
      "Complement\n",
      "Coarse Predictions: 0.48179446460980035\n",
      "Fine Predictions: 0.3169804900181488\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction using ONLY Continuous Features\")\n",
    "for clf, name in zip([GaussianNB(),MultinomialNB(),ComplementNB()], ['Gaussian', 'Multinomial', 'Complement']):\n",
    "    print(name)\n",
    "    clf.fit(X_train_con,Y_train_types)\n",
    "    s = clf.score(X_test_con,Y_test_types)\n",
    "    print(f\"Coarse Predictions: {s}\")\n",
    "    clf.fit(X_train_con,Y_train)\n",
    "    s = clf.score(X_test_con,Y_test)\n",
    "    print(f\"Fine Predictions: {s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction using ONLY Discrete Features\n",
      "Gaussian\n",
      "Coarse Predictions: 0.1847776769509982\n",
      "Fine Predictions: 0.037942377495462795\n",
      "Multinomial\n",
      "Coarse Predictions: 0.42678085299455537\n",
      "Fine Predictions: 0.16350952813067152\n",
      "Complement\n",
      "Coarse Predictions: 0.48060344827586204\n",
      "Fine Predictions: 0.41129764065335755\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction using ONLY Discrete Features\")\n",
    "for clf, name in zip([GaussianNB(),MultinomialNB(),ComplementNB()], ['Gaussian', 'Multinomial', 'Complement']):\n",
    "    print(name)\n",
    "    clf.fit(X_train_dis,Y_train_types)\n",
    "    s = clf.score(X_test_dis,Y_test_types)\n",
    "    print(f\"Coarse Predictions: {s}\")\n",
    "    clf.fit(X_train_dis,Y_train)\n",
    "    s = clf.score(X_test_dis,Y_test)\n",
    "    print(f\"Fine Predictions: {s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4  4  4 ... 32  4  4]\n",
      "Mixture 0.47515880217785844\n"
     ]
    }
   ],
   "source": [
    "clf_con, clf_dis = GaussianNB(), ComplementNB()\n",
    "clf_con.fit(X_train_con,Y_train_types)\n",
    "clf_dis.fit(X_train_dis,Y_train_types)\n",
    "label_classes = clf_con.classes_\n",
    "print(\"Mixture\",np.mean(mix_naive_bayes([(clf_con,X_test_con),(clf_dis,X_test_dis)],len(X_test_con),label_classes) == Y_test_types))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
